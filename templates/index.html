{% extends "base.html" %}

{% block title %}Hikaku Voice - STT Comparison{% endblock %}

{% block extra_styles %}
<style>
    .log-box {
        height: 300px;
        overflow-y: auto;
        border: 1px solid #e5e7eb;
        padding: 10px;
        border-radius: 4px;
        background: #f3f4f6;
        font-family: monospace;
    }

    .segment {
        margin-bottom: 8px;
        padding-bottom: 8px;
        border-bottom: 1px solid #ddd;
    }

    .latency {
        font-size: 0.8em;
        color: #6b7280;
        text-align: right;
    }

    .text {
        white-space: pre-wrap;
    }

    button.stop {
        background: #dc2626;
    }
</style>
{% endblock %}

{% block content %}
<div x-data="app()">
    <div class="status">
        <div>
            Status: <span x-text="status"></span>
        </div>
        <div>
            <button x-show="!isRecording" @click="startRecording">Start Recording</button>
            <button x-show="isRecording" class="stop" @click="stopRecording">Stop Recording</button>
        </div>
    </div>

    <!-- Dynamic Grid -->
    <div>
        <div class="grid" id="providers-grid">
            <!-- Columns will be injected here via JS -->
            <!-- Placeholder for loading state -->
            <div x-show="!providersLoaded" style="grid-column: 1/-1; text-align: center; color: #6b7280;">
                Connecting to server...
            </div>
        </div>
    </div>
</div>

<script>
    function app() {
        return {
            isRecording: false,
            status: 'Ready',
            audioContext: null,
            mediaStream: null,
            workletNode: null,
            socket: null,
            providersLoaded: false,

            async startRecording() {
                try {
                    this.status = 'Initializing...';

                    // 1. Setup WebSocket
                    // Use relative path for WS
                    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                    this.socket = new WebSocket(`${protocol}//${window.location.host}/ws/stt?response_format=html`);

                    this.socket.onopen = async () => {
                        console.log("WebSocket Connected");
                        this.status = 'Requesting Microphone...';
                        await this.setupAudio();
                    };

                    this.socket.onmessage = (event) => {
                        // Check for JSON config message first
                        try {
                            const data = JSON.parse(event.data);
                            if (data.type === "config") {
                                this.renderColumns(data.providers);
                                return;
                            } else if (data.type === "error") {
                                console.error("Server Error:", data.message);
                                this.status = "Server Error: " + data.message;
                                return;
                            }
                        } catch (e) {
                            // Not JSON, assume HTML
                        }

                        // POC: Manual OOB Swap Handler for HTML
                        const html = event.data;
                        // Basic check if it's the expected OOB div
                        if (typeof html === 'string' && html.trim().startsWith('<div id=')) {
                            // Create a temp container to parse the HTML
                            const temp = document.createElement('div');
                            temp.innerHTML = html;
                            const newElement = temp.firstElementChild; // The wrapper div

                            if (newElement) {
                                const targetId = newElement.getAttribute('id');
                                const swapMethod = newElement.getAttribute('hx-swap-oob');

                                const target = document.getElementById(targetId);
                                if (target && swapMethod === 'beforeend') {
                                    // Append the *content* of the wrapper, not the wrapper itself
                                    target.insertAdjacentHTML('beforeend', newElement.innerHTML);
                                    // Auto-scroll
                                    target.scrollTop = target.scrollHeight;
                                }
                            }
                        }
                    };

                    this.socket.onerror = (e) => {
                        console.error("WebSocket Error", e);
                        this.status = "WebSocket Error";
                    };

                } catch (e) {
                    console.error(e);
                    this.status = 'Error: ' + e.message;
                }
            },

            renderColumns(providers) {
                const grid = document.getElementById('providers-grid');
                grid.innerHTML = ''; // Clear placeholder

                providers.forEach(p => {
                    // p.id is the sanitized ID (e.g. deepgram-nova-2)
                    // p.name is the display name (e.g. Deepgram Nova 2)

                    const card = document.createElement('div');
                    card.className = 'card';

                    const title = document.createElement('h2');
                    title.textContent = p.name;

                    const logBox = document.createElement('div');
                    logBox.id = p.id + '-log'; // Matches backend: {safe_id}-log
                    logBox.className = 'log-box';

                    card.appendChild(title);
                    card.appendChild(logBox);
                    grid.appendChild(card);
                });

                this.providersLoaded = true;
                console.log("Rendered columns for:", providers);
            },

            async setupAudio() {
                try {
                    this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    this.audioContext = new AudioContext({ sampleRate: 16000 });

                    await this.audioContext.audioWorklet.addModule('/static/worklet.js');

                    const source = this.audioContext.createMediaStreamSource(this.mediaStream);
                    this.workletNode = new AudioWorkletNode(this.audioContext, 'pcm-processor');

                    source.connect(this.workletNode);
                    this.workletNode.connect(this.audioContext.destination);

                    let maxAmp = 0;
                    let lastSpeechTime = 0;
                    let isSpeaking = false;
                    const SILENCE_THRESHOLD = 500; // Int16 scale
                    const SILENCE_DURATION = 300; // ms to trigger EOS

                    this.workletNode.port.onmessage = (event) => {
                        if (this.socket && this.socket.readyState === WebSocket.OPEN) {
                            const float32Array = event.data;
                            const int16Array = new Int16Array(float32Array.length);
                            let currentMax = 0;

                            for (let i = 0; i < float32Array.length; i++) {
                                const s = Math.max(-1, Math.min(1, float32Array[i]));
                                int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                                if (Math.abs(int16Array[i]) > currentMax) currentMax = Math.abs(int16Array[i]);
                            }

                            this.socket.send(int16Array.buffer);

                            // VAD Logic
                            const now = Date.now();
                            if (currentMax > SILENCE_THRESHOLD) {
                                lastSpeechTime = now;
                                isSpeaking = true;
                            } else {
                                if (isSpeaking && (now - lastSpeechTime) > SILENCE_DURATION) {
                                    // Speech ended detected
                                    isSpeaking = false;
                                    console.log("VAD: Speech End Detected");
                                    // Send the ACTUAL time speech ended (lastSpeechTime), not current time.
                                    // Convert to seconds for backend compatibility
                                    this.socket.send(JSON.stringify({
                                        type: "vad_speech_end",
                                        timestamp: lastSpeechTime / 1000.0
                                    }));
                                }
                            }
                        }
                    };

                    this.status = 'Recording...';
                    this.isRecording = true;

                } catch (e) {
                    console.error("Audio Setup Error", e);
                    this.status = "Audio Error: " + e.message;
                }
            },

            stopRecording() {
                if (this.mediaStream) {
                    this.mediaStream.getTracks().forEach(track => track.stop());
                    this.mediaStream = null;
                }
                if (this.audioContext) {
                    this.audioContext.close();
                    this.audioContext = null;
                }
                if (this.socket) {
                    this.socket.close();
                    this.socket = null;
                }
                this.isRecording = false;
                this.status = 'Stopped';
            }
        }
    }
</script>
{% endblock %}
